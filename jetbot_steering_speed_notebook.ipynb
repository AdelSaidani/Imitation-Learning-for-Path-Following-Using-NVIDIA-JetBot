{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JetBot Steering + Speed - JetBot Notebook\n",
    "\n",
    "This notebook runs on your **JetBot** for data collection and inference.\n",
    "\n",
    "## Cells\n",
    "1. **Config** - All parameters (run first, always)\n",
    "2. **Speed Tuning** - Find MAX_SPEED before blur (run once during setup)\n",
    "3. **Data Collection** - Collect training data with joystick\n",
    "4. **Inference** - Run trained model autonomously\n",
    "5. **DAgger** - Collect corrections while model drives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 1: CONFIGURATION (Run this first!)\n",
    "# =============================================================================\n",
    "\n",
    "import torch\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# PATHS\n",
    "# -----------------------------------------------------------------------------\n",
    "DATASET_DIR = 'dataset_steering_speed_v1'\n",
    "DAGGER_DIR = 'dataset_steering_speed_dagger'\n",
    "MODEL_PATH = 'steering_speed_model_v1.pth'\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# CAMERA\n",
    "# -----------------------------------------------------------------------------\n",
    "CAMERA_WIDTH = 640\n",
    "CAMERA_HEIGHT = 480\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# PREPROCESSING (same as steering-only project)\n",
    "# -----------------------------------------------------------------------------\n",
    "CROP_TOP = 0.20\n",
    "CROP_BOTTOM = 0.00\n",
    "CROP_LEFT = 0.08\n",
    "CROP_RIGHT = 0.12\n",
    "INPUT_SIZE = (224, 224)\n",
    "\n",
    "# ImageNet normalization\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# SPEED CONTROL\n",
    "# -----------------------------------------------------------------------------\n",
    "MIN_SPEED = 0.12    # Speed in corners (safe, tested)\n",
    "MAX_SPEED = 0.25    # Speed on straights (tuned in Cell 2)\n",
    "\n",
    "# Model outputs speed_factor (0 to 1), we scale it:\n",
    "# actual_speed = MIN_SPEED + speed_factor * (MAX_SPEED - MIN_SPEED)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# STEERING CONTROL\n",
    "# -----------------------------------------------------------------------------\n",
    "STEERING_GAIN = 0.08\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# TIMING\n",
    "# -----------------------------------------------------------------------------\n",
    "LOOP_HZ = 20\n",
    "LOOP_SLEEP = 1.0 / LOOP_HZ\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# JOYSTICK MAPPING (Logitech controller)\n",
    "# -----------------------------------------------------------------------------\n",
    "AXIS_STEERING = 0   # Left stick X\n",
    "RT_BUTTON = 7       # Right trigger (analog 0-1)\n",
    "RB_BUTTON = 5       # Right bumper\n",
    "DEADZONE = 0.05\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# DEVICE\n",
    "# -----------------------------------------------------------------------------\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# HELPER FUNCTIONS\n",
    "# -----------------------------------------------------------------------------\n",
    "def speed_factor_to_actual(speed_factor):\n",
    "    \"\"\"Convert model output (0-1) to actual motor speed.\"\"\"\n",
    "    return MIN_SPEED + speed_factor * (MAX_SPEED - MIN_SPEED)\n",
    "\n",
    "def actual_to_speed_factor(actual_speed):\n",
    "    \"\"\"Convert actual motor speed to model target (0-1).\"\"\"\n",
    "    return (actual_speed - MIN_SPEED) / (MAX_SPEED - MIN_SPEED)\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"STEERING + SPEED CONFIG\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Device: {DEVICE}\")\n",
    "print(f\"Speed range: {MIN_SPEED} - {MAX_SPEED}\")\n",
    "print(f\"Dataset: {DATASET_DIR}\")\n",
    "print(f\"DAgger dir: {DAGGER_DIR}\")\n",
    "print(f\"Model: {MODEL_PATH}\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 2: SPEED TUNING (Run once during setup)\n",
    "# =============================================================================\n",
    "# Test different speeds on a straight section to find MAX_SPEED before blur.\n",
    "#\n",
    "# Instructions:\n",
    "# 1. Place robot at start of a straight section\n",
    "# 2. Press START\n",
    "# 3. Gradually increase speed slider\n",
    "# 4. Watch camera feed - when blur appears, press MARK BLUR POINT\n",
    "# 5. Press STOP and update MAX_SPEED in Cell 1\n",
    "\n",
    "import time\n",
    "import threading\n",
    "import cv2\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from jetbot import Camera, Robot, bgr8_to_jpeg\n",
    "\n",
    "# Hardware\n",
    "camera = Camera.instance(width=CAMERA_WIDTH, height=CAMERA_HEIGHT)\n",
    "robot = Robot()\n",
    "\n",
    "# Preprocessing\n",
    "def preprocess(img):\n",
    "    h, w = img.shape[:2]\n",
    "    y0, y1 = int(h * CROP_TOP), int(h * (1 - CROP_BOTTOM))\n",
    "    x0, x1 = int(w * CROP_LEFT), int(w * (1 - CROP_RIGHT))\n",
    "    return cv2.resize(img[y0:y1, x0:x1], INPUT_SIZE)\n",
    "\n",
    "def calculate_blur_metric(img):\n",
    "    \"\"\"Calculate Laplacian variance - lower = more blur.\"\"\"\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    return cv2.Laplacian(gray, cv2.CV_64F).var()\n",
    "\n",
    "# Widgets\n",
    "image_widget = widgets.Image(format='jpeg', width=224, height=224)\n",
    "speed_slider = widgets.FloatSlider(\n",
    "    value=MIN_SPEED, min=MIN_SPEED, max=0.35, step=0.01,\n",
    "    description='Speed:', layout=widgets.Layout(width='400px')\n",
    ")\n",
    "info_label = widgets.Label(value=f'Speed: {MIN_SPEED:.2f} | Blur: --')\n",
    "blur_indicator = widgets.HTML(value='<b style=\"color:green\">Image Quality: Good</b>')\n",
    "status_label = widgets.Label(value='Ready - Press START')\n",
    "\n",
    "start_btn = widgets.Button(description='START', button_style='success')\n",
    "stop_btn = widgets.Button(description='STOP', button_style='danger')\n",
    "mark_btn = widgets.Button(description='MARK BLUR POINT', button_style='warning')\n",
    "\n",
    "blur_point = {'speed': None}\n",
    "running = False\n",
    "\n",
    "def tuning_loop():\n",
    "    global running\n",
    "    blur_values = []\n",
    "    \n",
    "    while running:\n",
    "        raw = camera.value\n",
    "        processed = preprocess(raw)\n",
    "        \n",
    "        # Blur metric\n",
    "        blur = calculate_blur_metric(processed)\n",
    "        blur_values.append(blur)\n",
    "        if len(blur_values) > 10:\n",
    "            blur_values.pop(0)\n",
    "        avg_blur = sum(blur_values) / len(blur_values)\n",
    "        \n",
    "        # Update blur indicator\n",
    "        if avg_blur > 100:\n",
    "            blur_indicator.value = f'<b style=\"color:green\">Image Quality: Good ({avg_blur:.0f})</b>'\n",
    "        elif avg_blur > 50:\n",
    "            blur_indicator.value = f'<b style=\"color:orange\">Image Quality: OK ({avg_blur:.0f})</b>'\n",
    "        else:\n",
    "            blur_indicator.value = f'<b style=\"color:red\">Image Quality: BLURRY ({avg_blur:.0f})</b>'\n",
    "        \n",
    "        # Drive straight\n",
    "        speed = speed_slider.value\n",
    "        robot.left_motor.value = speed\n",
    "        robot.right_motor.value = speed\n",
    "        \n",
    "        # UI\n",
    "        image_widget.value = bgr8_to_jpeg(processed)\n",
    "        info_label.value = f'Speed: {speed:.2f} | Blur: {avg_blur:.0f}'\n",
    "        \n",
    "        time.sleep(0.05)\n",
    "    \n",
    "    robot.stop()\n",
    "\n",
    "def on_start(b):\n",
    "    global running\n",
    "    if not running:\n",
    "        running = True\n",
    "        status_label.value = 'RUNNING - Increase speed gradually'\n",
    "        threading.Thread(target=tuning_loop, daemon=True).start()\n",
    "\n",
    "def on_stop(b):\n",
    "    global running\n",
    "    running = False\n",
    "    robot.stop()\n",
    "    status_label.value = 'STOPPED'\n",
    "    if blur_point['speed']:\n",
    "        print(f\"\\nBlur detected at speed: {blur_point['speed']:.2f}\")\n",
    "        print(f\"Recommended MAX_SPEED: {blur_point['speed'] - 0.02:.2f}\")\n",
    "\n",
    "def on_mark(b):\n",
    "    blur_point['speed'] = speed_slider.value\n",
    "    status_label.value = f'MARKED blur at speed {blur_point[\"speed\"]:.2f}'\n",
    "\n",
    "start_btn.on_click(on_start)\n",
    "stop_btn.on_click(on_stop)\n",
    "mark_btn.on_click(on_mark)\n",
    "\n",
    "display(widgets.VBox([image_widget, speed_slider, blur_indicator, info_label, status_label]))\n",
    "display(widgets.HBox([start_btn, mark_btn, stop_btn]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup after speed tuning\n",
    "running = False\n",
    "robot.stop()\n",
    "camera.stop()\n",
    "print(\"Stopped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 3: DATA COLLECTION (Steering + Speed)\n",
    "# =============================================================================\n",
    "# Hold RB to drive and record. Left stick = steering, Right trigger = speed.\n",
    "\n",
    "import os\n",
    "import time\n",
    "import threading\n",
    "import cv2\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from jetbot import Camera, Robot, bgr8_to_jpeg\n",
    "\n",
    "# Create directory\n",
    "os.makedirs(DATASET_DIR, exist_ok=True)\n",
    "existing = len([f for f in os.listdir(DATASET_DIR) if f.endswith('.jpg')])\n",
    "print(f\"Dataset: {DATASET_DIR} ({existing} existing images)\")\n",
    "\n",
    "# Hardware\n",
    "camera = Camera.instance(width=CAMERA_WIDTH, height=CAMERA_HEIGHT)\n",
    "robot = Robot()\n",
    "\n",
    "# Preprocessing\n",
    "def preprocess(img):\n",
    "    h, w = img.shape[:2]\n",
    "    y0, y1 = int(h * CROP_TOP), int(h * (1 - CROP_BOTTOM))\n",
    "    x0, x1 = int(w * CROP_LEFT), int(w * (1 - CROP_RIGHT))\n",
    "    return cv2.resize(img[y0:y1, x0:x1], INPUT_SIZE)\n",
    "\n",
    "# Widgets\n",
    "image_widget = widgets.Image(format='jpeg', width=224, height=224)\n",
    "steering_slider = widgets.FloatSlider(value=0, min=-1, max=1, description='Steering:', disabled=True)\n",
    "speed_slider = widgets.FloatSlider(value=0, min=0, max=1, description='Speed:', disabled=True)\n",
    "count_widget = widgets.IntText(value=existing, description='Images:', disabled=True)\n",
    "status_label = widgets.Label(value='Ready - Press START')\n",
    "start_btn = widgets.Button(description='START', button_style='success')\n",
    "stop_btn = widgets.Button(description='STOP', button_style='danger')\n",
    "controller = widgets.Controller()\n",
    "\n",
    "running = False\n",
    "image_count = existing\n",
    "\n",
    "def collection_loop():\n",
    "    global running, image_count\n",
    "    \n",
    "    while running:\n",
    "        t0 = time.time()\n",
    "        \n",
    "        raw = camera.value\n",
    "        processed = preprocess(raw)\n",
    "        \n",
    "        # Read controller\n",
    "        try:\n",
    "            steering = controller.axes[AXIS_STEERING].value\n",
    "            speed_raw = controller.buttons[RT_BUTTON].value  # RT is 0-1\n",
    "            rb = controller.buttons[RB_BUTTON].value > 0.5\n",
    "        except:\n",
    "            steering, speed_raw, rb = 0.0, 0.0, False\n",
    "        \n",
    "        # Apply deadzone\n",
    "        if abs(steering) < DEADZONE:\n",
    "            steering = 0.0\n",
    "        \n",
    "        # Speed factor is directly from RT (0-1)\n",
    "        speed_factor = max(0, min(1, speed_raw))\n",
    "        actual_speed = speed_factor_to_actual(speed_factor)\n",
    "        \n",
    "        if rb:\n",
    "            # Drive\n",
    "            left = actual_speed + steering * STEERING_GAIN\n",
    "            right = actual_speed - steering * STEERING_GAIN\n",
    "            robot.left_motor.value = max(-1, min(1, left))\n",
    "            robot.right_motor.value = max(-1, min(1, right))\n",
    "            \n",
    "            # Save image with steering AND speed_factor\n",
    "            filename = f\"{int(time.time()*1000)}_{steering:.3f}_{speed_factor:.3f}.jpg\"\n",
    "            cv2.imwrite(os.path.join(DATASET_DIR, filename), processed)\n",
    "            image_count += 1\n",
    "            status_label.value = f'RECORDING ({image_count}) | Steer: {steering:.2f} | Speed: {speed_factor:.2f}'\n",
    "        else:\n",
    "            robot.stop()\n",
    "            status_label.value = f'PAUSED ({image_count}) - Hold RB to record'\n",
    "        \n",
    "        # UI\n",
    "        image_widget.value = bgr8_to_jpeg(processed)\n",
    "        steering_slider.value = steering\n",
    "        speed_slider.value = speed_factor\n",
    "        count_widget.value = image_count\n",
    "        \n",
    "        time.sleep(max(0, LOOP_SLEEP - (time.time() - t0)))\n",
    "    \n",
    "    robot.stop()\n",
    "    status_label.value = f'STOPPED ({image_count} images)'\n",
    "\n",
    "def on_start(b):\n",
    "    global running\n",
    "    if not running:\n",
    "        running = True\n",
    "        threading.Thread(target=collection_loop, daemon=True).start()\n",
    "\n",
    "def on_stop(b):\n",
    "    global running\n",
    "    running = False\n",
    "    robot.stop()\n",
    "\n",
    "start_btn.on_click(on_start)\n",
    "stop_btn.on_click(on_stop)\n",
    "\n",
    "print(\"Connect controller. Hold RB to drive and record.\")\n",
    "print(\"Left stick = steering, Right trigger = speed\")\n",
    "display(controller)\n",
    "display(widgets.VBox([image_widget, steering_slider, speed_slider, count_widget, status_label]))\n",
    "display(widgets.HBox([start_btn, stop_btn]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup after data collection\n",
    "running = False\n",
    "robot.stop()\n",
    "camera.stop()\n",
    "print(f\"Done. {image_count} images in {DATASET_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 4: INFERENCE (Autonomous Driving with Speed Control)\n",
    "# =============================================================================\n",
    "# Model predicts both steering and speed.\n",
    "# Speed factor (0-1) is converted to actual speed (MIN_SPEED to MAX_SPEED)\n",
    "\n",
    "import os\n",
    "import time\n",
    "import threading\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from jetbot import Camera, Robot, bgr8_to_jpeg\n",
    "\n",
    "# Model\n",
    "def get_model():\n",
    "    model = models.resnet18(pretrained=False)\n",
    "    model.fc = nn.Linear(model.fc.in_features, 2)  # 2 outputs: steering, speed\n",
    "    return model\n",
    "\n",
    "# Preprocessing\n",
    "def preprocess_for_inference(img):\n",
    "    h, w = img.shape[:2]\n",
    "    y0, y1 = int(h * CROP_TOP), int(h * (1 - CROP_BOTTOM))\n",
    "    x0, x1 = int(w * CROP_LEFT), int(w * (1 - CROP_RIGHT))\n",
    "    cropped = cv2.resize(img[y0:y1, x0:x1], INPUT_SIZE)\n",
    "    \n",
    "    rgb = cv2.cvtColor(cropped, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0\n",
    "    for i in range(3):\n",
    "        rgb[:,:,i] = (rgb[:,:,i] - IMAGENET_MEAN[i]) / IMAGENET_STD[i]\n",
    "    \n",
    "    tensor = torch.from_numpy(rgb.transpose(2,0,1)).unsqueeze(0)\n",
    "    return tensor, cropped\n",
    "\n",
    "# Load model\n",
    "print(f\"Loading {MODEL_PATH}...\")\n",
    "model = get_model()\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "model.to(DEVICE).eval()\n",
    "print(\"Model loaded.\")\n",
    "\n",
    "# Hardware\n",
    "camera = Camera.instance(width=CAMERA_WIDTH, height=CAMERA_HEIGHT)\n",
    "robot = Robot()\n",
    "\n",
    "# Widgets\n",
    "image_widget = widgets.Image(format='jpeg', width=224, height=224)\n",
    "steering_slider = widgets.FloatSlider(\n",
    "    value=0, min=-1, max=1, description='Steering:', disabled=True\n",
    ")\n",
    "speed_slider = widgets.FloatSlider(\n",
    "    value=0, min=0, max=1, description='Speed:', disabled=True\n",
    ")\n",
    "actual_speed_label = widgets.Label(value=f'Actual: {MIN_SPEED:.2f}')\n",
    "fps_widget = widgets.FloatText(value=0, description='FPS:', disabled=True)\n",
    "status_label = widgets.Label(value='Ready')\n",
    "\n",
    "start_btn = widgets.Button(description='START', button_style='success')\n",
    "stop_btn = widgets.Button(description='STOP', button_style='danger')\n",
    "\n",
    "running = False\n",
    "\n",
    "def inference_loop():\n",
    "    global running\n",
    "    frame_times = []\n",
    "    \n",
    "    while running:\n",
    "        t0 = time.time()\n",
    "        \n",
    "        # Get prediction\n",
    "        raw = camera.value\n",
    "        tensor, display_img = preprocess_for_inference(raw)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(tensor.to(DEVICE))\n",
    "            steering = outputs[0, 0].item()\n",
    "            speed_factor = outputs[0, 1].item()\n",
    "        \n",
    "        # Clamp values\n",
    "        steering = max(-1, min(1, steering))\n",
    "        speed_factor = max(0, min(1, speed_factor))\n",
    "        \n",
    "        # Convert speed factor to actual speed\n",
    "        actual_speed = speed_factor_to_actual(speed_factor)\n",
    "        \n",
    "        # Drive\n",
    "        left = actual_speed + steering * STEERING_GAIN\n",
    "        right = actual_speed - steering * STEERING_GAIN\n",
    "        robot.left_motor.value = max(-1, min(1, left))\n",
    "        robot.right_motor.value = max(-1, min(1, right))\n",
    "        \n",
    "        # FPS\n",
    "        frame_times.append(time.time() - t0)\n",
    "        if len(frame_times) > 30:\n",
    "            frame_times.pop(0)\n",
    "        fps = 1.0 / (sum(frame_times) / len(frame_times))\n",
    "        \n",
    "        # UI\n",
    "        image_widget.value = bgr8_to_jpeg(display_img)\n",
    "        steering_slider.value = steering\n",
    "        speed_slider.value = speed_factor\n",
    "        actual_speed_label.value = f'Actual: {actual_speed:.2f}'\n",
    "        fps_widget.value = round(fps, 1)\n",
    "        status_label.value = f'RUNNING | Steer: {steering:.2f} | Speed: {actual_speed:.2f}'\n",
    "        \n",
    "        # Loop timing\n",
    "        elapsed = time.time() - t0\n",
    "        if LOOP_SLEEP - elapsed > 0:\n",
    "            time.sleep(LOOP_SLEEP - elapsed)\n",
    "    \n",
    "    robot.stop()\n",
    "    status_label.value = 'STOPPED'\n",
    "\n",
    "def on_start(b):\n",
    "    global running\n",
    "    if not running:\n",
    "        running = True\n",
    "        threading.Thread(target=inference_loop, daemon=True).start()\n",
    "\n",
    "def on_stop(b):\n",
    "    global running\n",
    "    running = False\n",
    "    robot.stop()\n",
    "\n",
    "start_btn.on_click(on_start)\n",
    "stop_btn.on_click(on_stop)\n",
    "\n",
    "print(f\"Speed range: {MIN_SPEED} - {MAX_SPEED}\")\n",
    "display(widgets.VBox([image_widget, steering_slider, speed_slider, actual_speed_label, fps_widget, status_label]))\n",
    "display(widgets.HBox([start_btn, stop_btn]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup after inference\n",
    "running = False\n",
    "robot.stop()\n",
    "camera.stop()\n",
    "print(\"Stopped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 5: DAgger (Dataset Aggregation) - Steering + Speed\n",
    "# =============================================================================\n",
    "# Model drives autonomously. Hold RB to take over and save corrections.\n",
    "# When correcting: Left stick = steering, Right trigger = speed.\n",
    "#\n",
    "# The model predicts both steering and speed, but when you intervene,\n",
    "# YOUR steering and speed inputs are saved as corrections.\n",
    "\n",
    "import os\n",
    "import time\n",
    "import threading\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from jetbot import Camera, Robot, bgr8_to_jpeg\n",
    "\n",
    "# Create DAgger directory\n",
    "os.makedirs(DAGGER_DIR, exist_ok=True)\n",
    "existing = len([f for f in os.listdir(DAGGER_DIR) if f.endswith('.jpg')])\n",
    "print(f\"DAgger dir: {DAGGER_DIR} ({existing} existing corrections)\")\n",
    "\n",
    "# Model (2 outputs: steering, speed)\n",
    "def get_model():\n",
    "    model = models.resnet18(pretrained=False)\n",
    "    model.fc = nn.Linear(model.fc.in_features, 2)\n",
    "    return model\n",
    "\n",
    "# Preprocessing\n",
    "def preprocess_for_save(img):\n",
    "    h, w = img.shape[:2]\n",
    "    y0, y1 = int(h * CROP_TOP), int(h * (1 - CROP_BOTTOM))\n",
    "    x0, x1 = int(w * CROP_LEFT), int(w * (1 - CROP_RIGHT))\n",
    "    return cv2.resize(img[y0:y1, x0:x1], INPUT_SIZE)\n",
    "\n",
    "def preprocess_for_inference(img):\n",
    "    cropped = preprocess_for_save(img)\n",
    "    rgb = cv2.cvtColor(cropped, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0\n",
    "    for i in range(3):\n",
    "        rgb[:,:,i] = (rgb[:,:,i] - IMAGENET_MEAN[i]) / IMAGENET_STD[i]\n",
    "    tensor = torch.from_numpy(rgb.transpose(2,0,1)).unsqueeze(0)\n",
    "    return tensor, cropped\n",
    "\n",
    "# Load model\n",
    "print(f\"Loading {MODEL_PATH}...\")\n",
    "model = get_model()\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "model.to(DEVICE).eval()\n",
    "print(\"Model loaded.\")\n",
    "\n",
    "# Hardware\n",
    "camera = Camera.instance(width=CAMERA_WIDTH, height=CAMERA_HEIGHT)\n",
    "robot = Robot()\n",
    "\n",
    "# Widgets\n",
    "image_widget = widgets.Image(format='jpeg', width=224, height=224)\n",
    "model_steer_slider = widgets.FloatSlider(value=0, min=-1, max=1, description='Model Steer:', disabled=True)\n",
    "model_speed_slider = widgets.FloatSlider(value=0, min=0, max=1, description='Model Speed:', disabled=True)\n",
    "human_steer_slider = widgets.FloatSlider(value=0, min=-1, max=1, description='Human Steer:', disabled=True)\n",
    "human_speed_slider = widgets.FloatSlider(value=0, min=0, max=1, description='Human Speed:', disabled=True)\n",
    "count_widget = widgets.IntText(value=existing, description='Corrections:', disabled=True)\n",
    "status_label = widgets.Label(value='Ready')\n",
    "start_btn = widgets.Button(description='START', button_style='success')\n",
    "stop_btn = widgets.Button(description='STOP', button_style='danger')\n",
    "controller = widgets.Controller()\n",
    "\n",
    "running = False\n",
    "correction_count = existing\n",
    "\n",
    "def dagger_loop():\n",
    "    global running, correction_count\n",
    "    \n",
    "    while running:\n",
    "        t0 = time.time()\n",
    "        \n",
    "        raw = camera.value\n",
    "        tensor, display_img = preprocess_for_inference(raw)\n",
    "        \n",
    "        # Model prediction\n",
    "        with torch.no_grad():\n",
    "            outputs = model(tensor.to(DEVICE))\n",
    "            model_steer = outputs[0, 0].item()\n",
    "            model_speed_factor = outputs[0, 1].item()\n",
    "        \n",
    "        model_steer = max(-1, min(1, model_steer))\n",
    "        model_speed_factor = max(0, min(1, model_speed_factor))\n",
    "        \n",
    "        # Human input\n",
    "        try:\n",
    "            human_steer = controller.axes[AXIS_STEERING].value\n",
    "            human_speed_raw = controller.buttons[RT_BUTTON].value  # RT is 0-1\n",
    "            rb = controller.buttons[RB_BUTTON].value > 0.5\n",
    "        except:\n",
    "            human_steer, human_speed_raw, rb = 0.0, 0.0, False\n",
    "        \n",
    "        # Apply deadzone to steering\n",
    "        if abs(human_steer) < DEADZONE:\n",
    "            human_steer = 0.0\n",
    "        \n",
    "        human_speed_factor = max(0, min(1, human_speed_raw))\n",
    "        \n",
    "        # Who controls?\n",
    "        if rb:\n",
    "            # Human takes over\n",
    "            active_steer = human_steer\n",
    "            active_speed_factor = human_speed_factor\n",
    "            \n",
    "            # Save correction with BOTH steering and speed\n",
    "            processed = preprocess_for_save(raw)\n",
    "            filename = f\"{int(time.time()*1000)}_{human_steer:.3f}_{human_speed_factor:.3f}.jpg\"\n",
    "            cv2.imwrite(os.path.join(DAGGER_DIR, filename), processed)\n",
    "            correction_count += 1\n",
    "            status_label.value = f'CORRECTING - RB held ({correction_count})'\n",
    "        else:\n",
    "            # Model drives\n",
    "            active_steer = model_steer\n",
    "            active_speed_factor = model_speed_factor\n",
    "            status_label.value = f'MODEL DRIVING ({correction_count} corrections)'\n",
    "        \n",
    "        # Convert speed factor to actual speed and drive\n",
    "        actual_speed = speed_factor_to_actual(active_speed_factor)\n",
    "        left = actual_speed + active_steer * STEERING_GAIN\n",
    "        right = actual_speed - active_steer * STEERING_GAIN\n",
    "        robot.left_motor.value = max(-1, min(1, left))\n",
    "        robot.right_motor.value = max(-1, min(1, right))\n",
    "        \n",
    "        # UI\n",
    "        image_widget.value = bgr8_to_jpeg(display_img)\n",
    "        model_steer_slider.value = model_steer\n",
    "        model_speed_slider.value = model_speed_factor\n",
    "        human_steer_slider.value = human_steer\n",
    "        human_speed_slider.value = human_speed_factor\n",
    "        count_widget.value = correction_count\n",
    "        \n",
    "        time.sleep(max(0, LOOP_SLEEP - (time.time() - t0)))\n",
    "    \n",
    "    robot.stop()\n",
    "    status_label.value = f'STOPPED ({correction_count} corrections)'\n",
    "\n",
    "def on_start(b):\n",
    "    global running\n",
    "    if not running:\n",
    "        running = True\n",
    "        threading.Thread(target=dagger_loop, daemon=True).start()\n",
    "\n",
    "def on_stop(b):\n",
    "    global running\n",
    "    running = False\n",
    "    robot.stop()\n",
    "\n",
    "start_btn.on_click(on_start)\n",
    "stop_btn.on_click(on_stop)\n",
    "\n",
    "print(\"Connect controller. Model drives, hold RB to correct.\")\n",
    "print(\"When correcting: Left stick = steering, Right trigger = speed\")\n",
    "display(controller)\n",
    "display(widgets.VBox([\n",
    "    image_widget,\n",
    "    widgets.HTML('<b>Model:</b>'),\n",
    "    model_steer_slider, model_speed_slider,\n",
    "    widgets.HTML('<b>Human:</b>'),\n",
    "    human_steer_slider, human_speed_slider,\n",
    "    count_widget, status_label\n",
    "]))\n",
    "display(widgets.HBox([start_btn, stop_btn]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup after DAgger\n",
    "running = False\n",
    "robot.stop()\n",
    "camera.stop()\n",
    "print(f\"Done. {correction_count} corrections in {DAGGER_DIR}\")\n",
    "print(\"Copy DAgger folder to PC, combine with original data, and retrain.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
