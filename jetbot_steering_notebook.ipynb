{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JetBot Behavior Cloning - JetBot Notebook\n",
    "\n",
    "This notebook runs on your **JetBot** for data collection and inference.\n",
    "\n",
    "## Cells\n",
    "1. **Config** - All parameters (run first, always)\n",
    "2. **Crop Tuning** - Adjust crop visually (run once during setup)\n",
    "3. **Data Collection** - Collect training data with joystick\n",
    "4. **Inference** - Run trained model autonomously\n",
    "5. **DAgger** - Collect corrections while model drives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 1: CONFIGURATION (Run this first!)\n",
    "# =============================================================================\n",
    "\n",
    "import torch\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# PATHS\n",
    "# -----------------------------------------------------------------------------\n",
    "DATASET_DIR = 'dataset_v1'\n",
    "DAGGER_DIR = 'dataset_dagger'\n",
    "MODEL_PATH = 'steering_model_v1.pth'\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# CAMERA\n",
    "# -----------------------------------------------------------------------------\n",
    "CAMERA_WIDTH = 640\n",
    "CAMERA_HEIGHT = 480\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# PREPROCESSING (must match PC training notebook)\n",
    "# -----------------------------------------------------------------------------\n",
    "CROP_TOP = 0.20\n",
    "CROP_BOTTOM = 0.00\n",
    "CROP_LEFT = 0.08\n",
    "CROP_RIGHT = 0.12\n",
    "INPUT_SIZE = (224, 224)\n",
    "\n",
    "# ImageNet normalization\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# MOTOR CONTROL\n",
    "# -----------------------------------------------------------------------------\n",
    "FORWARD_SPEED = 0.12\n",
    "STEERING_GAIN = 0.08\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# TIMING\n",
    "# -----------------------------------------------------------------------------\n",
    "LOOP_HZ = 20\n",
    "LOOP_SLEEP = 1.0 / LOOP_HZ\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# JOYSTICK \n",
    "# -----------------------------------------------------------------------------\n",
    "AXIS_STEERING = 0  # Left stick X\n",
    "RB_BUTTON = 5      # Right bumper\n",
    "DEADZONE = 0.05\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# DEVICE\n",
    "# -----------------------------------------------------------------------------\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f\"Configuration loaded. Device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 2: CROP TUNING (Run once during setup)\n",
    "# =============================================================================\n",
    "# Adjust sliders to find optimal crop values, then update Cell 1\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from jetbot import Camera, bgr8_to_jpeg\n",
    "\n",
    "camera = Camera.instance(width=CAMERA_WIDTH, height=CAMERA_HEIGHT)\n",
    "\n",
    "# Widgets\n",
    "raw_widget = widgets.Image(format='jpeg', width=320, height=240)\n",
    "crop_widget = widgets.Image(format='jpeg', width=224, height=224)\n",
    "top_slider = widgets.FloatSlider(value=CROP_TOP, min=0, max=0.6, step=0.02, description='Top:')\n",
    "bottom_slider = widgets.FloatSlider(value=CROP_BOTTOM, min=0, max=0.5, step=0.02, description='Bottom:')\n",
    "left_slider = widgets.FloatSlider(value=CROP_LEFT, min=0, max=0.3, step=0.02, description='Left:')\n",
    "right_slider = widgets.FloatSlider(value=CROP_RIGHT, min=0, max=0.3, step=0.02, description='Right:')\n",
    "info_label = widgets.Label()\n",
    "stop_btn = widgets.Button(description='STOP', button_style='danger')\n",
    "\n",
    "running = True\n",
    "\n",
    "def update(change=None):\n",
    "    if not running:\n",
    "        return\n",
    "    raw = camera.value\n",
    "    h, w = raw.shape[:2]\n",
    "    \n",
    "    t, b, l, r = top_slider.value, bottom_slider.value, left_slider.value, right_slider.value\n",
    "    y0, y1 = int(h * t), int(h * (1 - b))\n",
    "    x0, x1 = int(w * l), int(w * (1 - r))\n",
    "    \n",
    "    cropped = cv2.resize(raw[y0:y1, x0:x1], (224, 224))\n",
    "    \n",
    "    raw_viz = raw.copy()\n",
    "    cv2.rectangle(raw_viz, (x0, y0), (x1, y1), (0, 255, 0), 2)\n",
    "    \n",
    "    raw_widget.value = bgr8_to_jpeg(raw_viz)\n",
    "    crop_widget.value = bgr8_to_jpeg(cropped)\n",
    "    info_label.value = f'{w}x{h} -> {x1-x0}x{y1-y0} -> 224x224'\n",
    "\n",
    "def stop(b):\n",
    "    global running\n",
    "    running = False\n",
    "    camera.stop()\n",
    "    print(f\"\\nCopy these values to Cell 1:\")\n",
    "    print(f\"CROP_TOP = {top_slider.value:.2f}\")\n",
    "    print(f\"CROP_BOTTOM = {bottom_slider.value:.2f}\")\n",
    "    print(f\"CROP_LEFT = {left_slider.value:.2f}\")\n",
    "    print(f\"CROP_RIGHT = {right_slider.value:.2f}\")\n",
    "\n",
    "stop_btn.on_click(stop)\n",
    "for s in [top_slider, bottom_slider, left_slider, right_slider]:\n",
    "    s.observe(update, names='value')\n",
    "camera.observe(update, names='value')\n",
    "\n",
    "display(widgets.HBox([raw_widget, crop_widget]))\n",
    "display(top_slider, bottom_slider, left_slider, right_slider)\n",
    "display(info_label, stop_btn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 3: DATA COLLECTION\n",
    "# =============================================================================\n",
    "# Hold RB to drive forward and record. Use left stick to steer.\n",
    "\n",
    "import os\n",
    "import time\n",
    "import threading\n",
    "import cv2\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from jetbot import Camera, Robot, bgr8_to_jpeg\n",
    "\n",
    "# Create directory\n",
    "os.makedirs(DATASET_DIR, exist_ok=True)\n",
    "existing = len([f for f in os.listdir(DATASET_DIR) if f.endswith('.jpg')])\n",
    "print(f\"Dataset: {DATASET_DIR} ({existing} existing images)\")\n",
    "\n",
    "# Hardware\n",
    "camera = Camera.instance(width=CAMERA_WIDTH, height=CAMERA_HEIGHT)\n",
    "robot = Robot()\n",
    "\n",
    "# Preprocessing\n",
    "def preprocess(img):\n",
    "    h, w = img.shape[:2]\n",
    "    y0, y1 = int(h * CROP_TOP), int(h * (1 - CROP_BOTTOM))\n",
    "    x0, x1 = int(w * CROP_LEFT), int(w * (1 - CROP_RIGHT))\n",
    "    return cv2.resize(img[y0:y1, x0:x1], INPUT_SIZE)\n",
    "\n",
    "# Widgets\n",
    "image_widget = widgets.Image(format='jpeg', width=224, height=224)\n",
    "steering_slider = widgets.FloatSlider(value=0, min=-1, max=1, description='Steering:', disabled=True)\n",
    "count_widget = widgets.IntText(value=existing, description='Images:', disabled=True)\n",
    "status_label = widgets.Label(value='Ready - Press START')\n",
    "start_btn = widgets.Button(description='START', button_style='success')\n",
    "stop_btn = widgets.Button(description='STOP', button_style='danger')\n",
    "controller = widgets.Controller()\n",
    "\n",
    "running = False\n",
    "image_count = existing\n",
    "\n",
    "def collection_loop():\n",
    "    global running, image_count\n",
    "    \n",
    "    while running:\n",
    "        t0 = time.time()\n",
    "        \n",
    "        # Read joystick\n",
    "        try:\n",
    "            steering = controller.axes[AXIS_STEERING].value\n",
    "            rb = controller.buttons[RB_BUTTON].value > 0.5\n",
    "        except:\n",
    "            steering, rb = 0.0, False\n",
    "        \n",
    "        if abs(steering) < DEADZONE:\n",
    "            steering = 0.0\n",
    "        \n",
    "        # Process frame\n",
    "        raw = camera.value\n",
    "        processed = preprocess(raw)\n",
    "        \n",
    "        if rb:\n",
    "            # Drive and record\n",
    "            left = FORWARD_SPEED + steering * STEERING_GAIN\n",
    "            right = FORWARD_SPEED - steering * STEERING_GAIN\n",
    "            robot.left_motor.value = max(-1, min(1, left))\n",
    "            robot.right_motor.value = max(-1, min(1, right))\n",
    "            \n",
    "            # Save\n",
    "            filename = f\"{int(time.time()*1000)}_{steering:.3f}.jpg\"\n",
    "            cv2.imwrite(os.path.join(DATASET_DIR, filename), processed)\n",
    "            image_count += 1\n",
    "            \n",
    "            status_label.value = f'RECORDING ({image_count} images)'\n",
    "        else:\n",
    "            robot.stop()\n",
    "            status_label.value = f'PAUSED - Hold RB ({image_count} images)'\n",
    "        \n",
    "        # Update UI\n",
    "        image_widget.value = bgr8_to_jpeg(processed)\n",
    "        steering_slider.value = steering\n",
    "        count_widget.value = image_count\n",
    "        \n",
    "        time.sleep(max(0, LOOP_SLEEP - (time.time() - t0)))\n",
    "    \n",
    "    robot.stop()\n",
    "    status_label.value = f'STOPPED ({image_count} images)'\n",
    "\n",
    "def on_start(b):\n",
    "    global running\n",
    "    if not running:\n",
    "        running = True\n",
    "        threading.Thread(target=collection_loop, daemon=True).start()\n",
    "\n",
    "def on_stop(b):\n",
    "    global running\n",
    "    running = False\n",
    "    robot.stop()\n",
    "\n",
    "start_btn.on_click(on_start)\n",
    "stop_btn.on_click(on_stop)\n",
    "\n",
    "print(\"Connect controller and press START\")\n",
    "display(controller)\n",
    "display(widgets.VBox([image_widget, steering_slider, count_widget, status_label]))\n",
    "display(widgets.HBox([start_btn, stop_btn]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup after data collection\n",
    "running = False\n",
    "robot.stop()\n",
    "camera.stop()\n",
    "print(f\"Done. {image_count} images in {DATASET_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 4: INFERENCE (Autonomous Driving)\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "import time\n",
    "import threading\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from jetbot import Camera, Robot, bgr8_to_jpeg\n",
    "\n",
    "# Model\n",
    "def get_model():\n",
    "    model = models.resnet18(pretrained=False)\n",
    "    model.fc = nn.Linear(model.fc.in_features, 1)\n",
    "    return model\n",
    "\n",
    "# Preprocessing\n",
    "def preprocess_for_inference(img):\n",
    "    h, w = img.shape[:2]\n",
    "    y0, y1 = int(h * CROP_TOP), int(h * (1 - CROP_BOTTOM))\n",
    "    x0, x1 = int(w * CROP_LEFT), int(w * (1 - CROP_RIGHT))\n",
    "    cropped = cv2.resize(img[y0:y1, x0:x1], INPUT_SIZE)\n",
    "    \n",
    "    rgb = cv2.cvtColor(cropped, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0\n",
    "    for i in range(3):\n",
    "        rgb[:,:,i] = (rgb[:,:,i] - IMAGENET_MEAN[i]) / IMAGENET_STD[i]\n",
    "    \n",
    "    tensor = torch.from_numpy(rgb.transpose(2,0,1)).unsqueeze(0)\n",
    "    return tensor, cropped\n",
    "\n",
    "# Load model\n",
    "print(f\"Loading {MODEL_PATH}...\")\n",
    "model = get_model()\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "model.to(DEVICE).eval()\n",
    "print(\"Model loaded.\")\n",
    "\n",
    "# Hardware\n",
    "camera = Camera.instance(width=CAMERA_WIDTH, height=CAMERA_HEIGHT)\n",
    "robot = Robot()\n",
    "\n",
    "# Widgets\n",
    "image_widget = widgets.Image(format='jpeg', width=224, height=224)\n",
    "steering_slider = widgets.FloatSlider(value=0, min=-1, max=1, description='Steering:', disabled=True)\n",
    "fps_widget = widgets.FloatText(value=0, description='FPS:', disabled=True)\n",
    "status_label = widgets.Label(value='Ready')\n",
    "start_btn = widgets.Button(description='START', button_style='success')\n",
    "stop_btn = widgets.Button(description='STOP', button_style='danger')\n",
    "\n",
    "running = False\n",
    "\n",
    "def inference_loop():\n",
    "    global running\n",
    "    frame_times = []\n",
    "    \n",
    "    while running:\n",
    "        t0 = time.time()\n",
    "        \n",
    "        # Get prediction\n",
    "        raw = camera.value\n",
    "        tensor, display_img = preprocess_for_inference(raw)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            steering = model(tensor.to(DEVICE)).item()\n",
    "        steering = max(-1, min(1, steering))\n",
    "        \n",
    "        # Drive\n",
    "        left = FORWARD_SPEED + steering * STEERING_GAIN\n",
    "        right = FORWARD_SPEED - steering * STEERING_GAIN\n",
    "        robot.left_motor.value = max(-1, min(1, left))\n",
    "        robot.right_motor.value = max(-1, min(1, right))\n",
    "        \n",
    "        # FPS\n",
    "        frame_times.append(time.time() - t0)\n",
    "        if len(frame_times) > 30:\n",
    "            frame_times.pop(0)\n",
    "        fps = 1.0 / (sum(frame_times) / len(frame_times))\n",
    "        \n",
    "        # UI\n",
    "        image_widget.value = bgr8_to_jpeg(display_img)\n",
    "        steering_slider.value = steering\n",
    "        fps_widget.value = round(fps, 1)\n",
    "        status_label.value = f'RUNNING | Steer: {steering:.2f}'\n",
    "        \n",
    "        time.sleep(max(0, LOOP_SLEEP - (time.time() - t0)))\n",
    "    \n",
    "    robot.stop()\n",
    "    status_label.value = 'STOPPED'\n",
    "\n",
    "def on_start(b):\n",
    "    global running\n",
    "    if not running:\n",
    "        running = True\n",
    "        threading.Thread(target=inference_loop, daemon=True).start()\n",
    "\n",
    "def on_stop(b):\n",
    "    global running\n",
    "    running = False\n",
    "    robot.stop()\n",
    "\n",
    "start_btn.on_click(on_start)\n",
    "stop_btn.on_click(on_stop)\n",
    "\n",
    "display(widgets.VBox([image_widget, steering_slider, fps_widget, status_label]))\n",
    "display(widgets.HBox([start_btn, stop_btn]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup after inference\n",
    "running = False\n",
    "robot.stop()\n",
    "camera.stop()\n",
    "print(\"Stopped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 5: DAgger (Dataset Aggregation)\n",
    "# =============================================================================\n",
    "# Model drives. Hold RB to take over and save corrections.\n",
    "\n",
    "import os\n",
    "import time\n",
    "import threading\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from jetbot import Camera, Robot, bgr8_to_jpeg\n",
    "\n",
    "# Create DAgger directory\n",
    "os.makedirs(DAGGER_DIR, exist_ok=True)\n",
    "existing = len([f for f in os.listdir(DAGGER_DIR) if f.endswith('.jpg')])\n",
    "print(f\"DAgger dir: {DAGGER_DIR} ({existing} existing corrections)\")\n",
    "\n",
    "# Model\n",
    "def get_model():\n",
    "    model = models.resnet18(pretrained=False)\n",
    "    model.fc = nn.Linear(model.fc.in_features, 1)\n",
    "    return model\n",
    "\n",
    "# Preprocessing\n",
    "def preprocess_for_save(img):\n",
    "    h, w = img.shape[:2]\n",
    "    y0, y1 = int(h * CROP_TOP), int(h * (1 - CROP_BOTTOM))\n",
    "    x0, x1 = int(w * CROP_LEFT), int(w * (1 - CROP_RIGHT))\n",
    "    return cv2.resize(img[y0:y1, x0:x1], INPUT_SIZE)\n",
    "\n",
    "def preprocess_for_inference(img):\n",
    "    cropped = preprocess_for_save(img)\n",
    "    rgb = cv2.cvtColor(cropped, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0\n",
    "    for i in range(3):\n",
    "        rgb[:,:,i] = (rgb[:,:,i] - IMAGENET_MEAN[i]) / IMAGENET_STD[i]\n",
    "    tensor = torch.from_numpy(rgb.transpose(2,0,1)).unsqueeze(0)\n",
    "    return tensor, cropped\n",
    "\n",
    "# Load model\n",
    "print(f\"Loading {MODEL_PATH}...\")\n",
    "model = get_model()\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "model.to(DEVICE).eval()\n",
    "print(\"Model loaded.\")\n",
    "\n",
    "# Hardware\n",
    "camera = Camera.instance(width=CAMERA_WIDTH, height=CAMERA_HEIGHT)\n",
    "robot = Robot()\n",
    "\n",
    "# Widgets\n",
    "image_widget = widgets.Image(format='jpeg', width=224, height=224)\n",
    "model_slider = widgets.FloatSlider(value=0, min=-1, max=1, description='Model:', disabled=True)\n",
    "human_slider = widgets.FloatSlider(value=0, min=-1, max=1, description='Human:', disabled=True)\n",
    "count_widget = widgets.IntText(value=existing, description='Corrections:', disabled=True)\n",
    "status_label = widgets.Label(value='Ready')\n",
    "start_btn = widgets.Button(description='START', button_style='success')\n",
    "stop_btn = widgets.Button(description='STOP', button_style='danger')\n",
    "controller = widgets.Controller()\n",
    "\n",
    "running = False\n",
    "correction_count = existing\n",
    "\n",
    "def dagger_loop():\n",
    "    global running, correction_count\n",
    "    \n",
    "    while running:\n",
    "        t0 = time.time()\n",
    "        \n",
    "        raw = camera.value\n",
    "        tensor, display_img = preprocess_for_inference(raw)\n",
    "        \n",
    "        # Model prediction\n",
    "        with torch.no_grad():\n",
    "            model_steer = model(tensor.to(DEVICE)).item()\n",
    "        model_steer = max(-1, min(1, model_steer))\n",
    "        \n",
    "        # Human input\n",
    "        try:\n",
    "            human_steer = controller.axes[AXIS_STEERING].value\n",
    "            rb = controller.buttons[RB_BUTTON].value > 0.5\n",
    "        except:\n",
    "            human_steer, rb = 0.0, False\n",
    "        \n",
    "        if abs(human_steer) < DEADZONE:\n",
    "            human_steer = 0.0\n",
    "        \n",
    "        # Who controls?\n",
    "        if rb:\n",
    "            active_steer = human_steer\n",
    "            # Save correction\n",
    "            processed = preprocess_for_save(raw)\n",
    "            filename = f\"{int(time.time()*1000)}_{human_steer:.3f}.jpg\"\n",
    "            cv2.imwrite(os.path.join(DAGGER_DIR, filename), processed)\n",
    "            correction_count += 1\n",
    "            status_label.value = f'CORRECTING - RB held ({correction_count})'\n",
    "        else:\n",
    "            active_steer = model_steer\n",
    "            status_label.value = f'MODEL DRIVING ({correction_count} corrections)'\n",
    "        \n",
    "        # Drive\n",
    "        left = FORWARD_SPEED + active_steer * STEERING_GAIN\n",
    "        right = FORWARD_SPEED - active_steer * STEERING_GAIN\n",
    "        robot.left_motor.value = max(-1, min(1, left))\n",
    "        robot.right_motor.value = max(-1, min(1, right))\n",
    "        \n",
    "        # UI\n",
    "        image_widget.value = bgr8_to_jpeg(display_img)\n",
    "        model_slider.value = model_steer\n",
    "        human_slider.value = human_steer\n",
    "        count_widget.value = correction_count\n",
    "        \n",
    "        time.sleep(max(0, LOOP_SLEEP - (time.time() - t0)))\n",
    "    \n",
    "    robot.stop()\n",
    "    status_label.value = f'STOPPED ({correction_count} corrections)'\n",
    "\n",
    "def on_start(b):\n",
    "    global running\n",
    "    if not running:\n",
    "        running = True\n",
    "        threading.Thread(target=dagger_loop, daemon=True).start()\n",
    "\n",
    "def on_stop(b):\n",
    "    global running\n",
    "    running = False\n",
    "    robot.stop()\n",
    "\n",
    "start_btn.on_click(on_start)\n",
    "stop_btn.on_click(on_stop)\n",
    "\n",
    "print(\"Connect controller. Model drives, hold RB to correct.\")\n",
    "display(controller)\n",
    "display(widgets.VBox([image_widget, model_slider, human_slider, count_widget, status_label]))\n",
    "display(widgets.HBox([start_btn, stop_btn]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup after DAgger\n",
    "running = False\n",
    "robot.stop()\n",
    "camera.stop()\n",
    "print(f\"Done. {correction_count} corrections in {DAGGER_DIR}\")\n",
    "print(\"Copy DAgger folder to PC, combine with original data, and retrain.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
